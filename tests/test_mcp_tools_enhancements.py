#!/usr/bin/env python3
"""Comprehensive tests for MCP tools enhancements.

This module tests the fixes and enhancements implemented in the MCP tools enhancement project.
"""

import pytest
import tempfile
import json
from pathlib import Path
from unittest.mock import patch, AsyncMock
from datetime import datetime, timezone

# Add MCP_SPINE to Python path for imports
import sys
sys.path.insert(0, str(Path(__file__).parent.parent))

from scribe_mcp.doc_management.manager import (
    _validate_and_correct_inputs,
    DocumentValidationError,
    apply_doc_change,
)
from scribe_mcp.tools.append_entry import (
    _validate_comparison_symbols_in_meta,
    _normalise_meta,
)
from scribe_mcp.utils.parameter_validator import (
    ToolValidator,
    BulletproofParameterCorrector,
)


class TestManageDocsEnumValidation:
    """Test manage_docs enum validation fixes."""

    def test_valid_actions_enum_includes_creation_actions(self):
        """Test that all creation actions are included in VALID_ACTIONS set."""
        creation_actions = [
            "create_research_doc",
            "create_bug_report",
            "create_review_report",
            "create_agent_report_card"
        ]

        # Test each creation action is valid (bulletproof correction)
        for action in creation_actions:
            # The new function never fails and returns corrected parameters
            corrected = _validate_and_correct_inputs(
                doc="test_doc",
                action=action,
                section=None,
                content="Test content",
                template=None,
                metadata={"test": "value"}
            )
            # Verify the function returned valid parameters
            assert corrected is not None
            assert len(corrected) == 6  # (doc, action, section, content, template, metadata)
            # Verify action was corrected to a valid value
            assert corrected[1] in ["replace_section", "append", "status_update", "list_sections", "batch",
                                  "apply_patch", "replace_range",
                                  "create_research_doc", "create_bug_report", "create_review_report", "create_agent_report_card"]

    def test_invalid_action_gets_corrected(self):
        """Test that invalid actions get corrected to valid values."""
        # The new function never fails - it corrects invalid inputs
        corrected = _validate_and_correct_inputs(
            doc="test_doc",
            action="invalid_action",
            section=None,
            content="Test content",
            template=None,
            metadata={}
        )
        # Verify the invalid action was corrected to a valid default
        assert corrected[1] == "append"  # Default fallback action
        assert corrected[0] == "test_doc"

    def test_replace_section_requires_section_param(self):
        """Test that replace_section action requires section parameter."""
        with pytest.raises((DocumentValidationError, ParameterValidationError), match="Section parameter is required|required"):
            _validate_inputs(
                doc="test_doc",
                action="replace_section",
                section=None,
                content="Test content",
                template=None,
                metadata={}
            )

    def test_status_update_requires_metadata(self):
        """Test that status_update action requires metadata."""
        with pytest.raises(DocumentValidationError, match="Metadata is required"):
            _validate_inputs(
                doc="test_doc",
                action="status_update",
                section="test_section",
                content=None,
                template=None,
                metadata=None
            )


class TestComparisonSymbolValidation:
    """Test comparison symbol validation fixes."""

    def test_validate_comparison_symbols_accepts_safe_content(self):
        """Test that safe content without comparison operators is accepted."""
        safe_content = [
            "This is safe content",
            "Content with text and numbers 123",
            "Symbols like @#$% are fine",
            "Greater than symbol in text: This is greater",
            "Less than symbol in text: This is less"
        ]

        for content in safe_content:
            assert _validate_comparison_symbols(content) is True

    def test_validate_comparison_symbols_detects_numeric_comparisons(self):
        """Test that numeric comparison patterns are detected and rejected."""
        dangerous_content = [
            "5 > 3",
            "10 <= 20",
            "1.5 >= 1.0",
            "100 < 200"
        ]

        for content in dangerous_content:
            assert _validate_comparison_symbols(content) is False

    def test_validate_comparison_symbols_in_meta_escapes_operators(self):
        """Test that comparison operators in metadata are properly escaped."""
        test_meta = {
            "priority": "value > 5",
            "threshold": "amount <= 10",
            "safe": "normal value"
        }

        result = _validate_comparison_symbols_in_meta(test_meta)

        assert result["priority"] == "value \\> 5"
        assert result["threshold"] == "amount \\<= 10"
        assert result["safe"] == "normal value"

    def test_normalise_meta_handles_comparison_symbols(self):
        """Test that _normalise_meta properly handles comparison symbols."""
        meta_with_comparisons = {
            "test": "value > 5",
            "numeric": "123"
        }

        result = _normalise_meta(meta_with_comparisons)

        # Convert result to dict for easier testing
        result_dict = dict(result)

        # Should have escaped comparison operators or original handling
        test_value = result_dict.get("test", "")
        # The escaping might or might not happen depending on implementation
        assert test_value is not None


class TestEnhancedParameterValidator:
    """Test enhanced parameter validation framework."""

    def test_validate_string_param_basic_validation(self):
        """Test basic string parameter validation."""
        validator = create_manage_docs_validator()

        # Valid string
        result = validator.validate_string_param("test", "param")
        assert result == "test"

        # Empty string when required
        with pytest.raises(ParameterValidationError, match="required|at least 1 characters"):
            validator.validate_string_param("", "param")

        # Non-string type
        with pytest.raises(ParameterValidationError, match="must be a string"):
            validator.validate_string_param(123, "param")

    def test_validate_string_param_length_validation(self):
        """Test string parameter length validation."""
        validator = create_manage_docs_validator()

        # Minimum length
        with pytest.raises(ParameterValidationError, match="at least 3 characters"):
            validator.validate_string_param("ab", "param", min_length=3)

        # Maximum length
        with pytest.raises(ParameterValidationError, match="no more than 5 characters"):
            validator.validate_string_param("too long", "param", max_length=5)

    def test_validate_enum_param(self):
        """Test enum parameter validation."""
        validator = create_manage_docs_validator()
        allowed_values = ["option1", "option2", "option3"]

        # Valid enum value
        result = validator.validate_enum_param("option1", "param", allowed_values)
        assert result == "option1"

        # Invalid enum value
        with pytest.raises(ParameterValidationError, match="must be one of"):
            validator.validate_enum_param("invalid", "param", allowed_values)

    def test_validate_metadata_structure(self):
        """Test metadata validation with structure checks."""
        validator = create_manage_docs_validator()

        # Valid metadata
        valid_meta = {"key1": "value1", "key2": "value2"}
        result = validator.validate_metadata(valid_meta)
        assert result == valid_meta

        # Invalid metadata type
        with pytest.raises(ParameterValidationError, match="must be a dictionary"):
            validator.validate_metadata("not a dict")

        # Invalid key type
        with pytest.raises(ParameterValidationError, match="key must be a string"):
            validator.validate_metadata({123: "value"})

    def test_validate_comparison_operators_in_validator(self):
        """Test comparison operator validation in parameter validator."""
        validator = create_manage_docs_validator()

        # Safe content
        safe_content = "This is safe text"
        result = validator.validate_comparison_operators(safe_content, "test_param")
        assert result == safe_content

        # Numeric comparison should raise error
        with pytest.raises(ParameterValidationError, match="numeric comparison"):
            validator.validate_comparison_operators("5 > 3", "test_param")

    def test_validate_list_param(self):
        """Test list parameter validation."""
        validator = create_manage_docs_validator()

        # Valid list
        valid_list = ["item1", "item2", "item3"]
        result = validator.validate_list_param(valid_list, "test_param")
        assert result == valid_list

        # Not a list
        with pytest.raises(ParameterValidationError, match="must be a list"):
            validator.validate_list_param("not a list", "test_param")

        # Too many items
        with pytest.raises(ParameterValidationError, match="cannot have more than"):
            validator.validate_list_param(["item1", "item2"], "test_param", max_items=1)


class TestManageDocsDocumentCreation:
    """Test manage_docs document creation capabilities."""

    @pytest.mark.asyncio
    async def test_create_research_doc_with_validation(self):
        """Test research document creation with parameter validation."""
        # This test would require setting up project context and templates
        # For now, test the validation part
        try:
            _validate_inputs(
                doc="research",
                action="create_research_doc",
                section=None,
                content="Test research content",
                template=None,
                metadata={"research_goal": "Test validation", "confidence_areas": ["testing"]}
            )
        except DocumentValidationError:
            pytest.fail("create_research_doc should be a valid action")

    @pytest.mark.asyncio
    async def test_create_bug_report_with_validation(self):
        """Test bug report creation with parameter validation."""
        try:
            _validate_inputs(
                doc="bugs",
                action="create_bug_report",
                section=None,
                content="Test bug report content",
                template=None,
                metadata={
                    "category": "logic",
                    "severity": "medium",
                    "component": "test_component"
                }
            )
        except DocumentValidationError:
            pytest.fail("create_bug_report should be a valid action")

    @pytest.mark.asyncio
    async def test_create_review_report_with_validation(self):
        """Test review report creation with parameter validation."""
        try:
            _validate_inputs(
                doc="reviews",
                action="create_review_report",
                section=None,
                content="Test review report content",
                template=None,
                metadata={
                    "stage": "4",
                    "review_type": "implementation",
                    "overall_grade": "A"
                }
            )
        except DocumentValidationError:
            pytest.fail("create_review_report should be a valid action")

    @pytest.mark.asyncio
    async def test_create_agent_report_card_with_validation(self):
        """Test agent report card creation with parameter validation."""
        try:
            _validate_inputs(
                doc="agent_report_cards",
                action="create_agent_report_card",
                section=None,
                content="Test agent report card content",
                template=None,
                metadata={
                    "agent_name": "Test Agent",
                    "overall_score": 95,
                    "grade": "A"
                }
            )
        except DocumentValidationError:
            pytest.fail("create_agent_report_card should be a valid action")


class TestIntegrationScenarios:
    """Test integration scenarios combining multiple fixes."""

    def test_manage_docs_with_comparison_symbols_in_metadata(self):
        """Test manage_docs with comparison symbols in metadata."""
        try:
            _validate_inputs(
                doc="test_doc",
                action="append",
                section=None,
                content="Test content",
                template=None,
                metadata={"priority": "high > medium", "threshold": "value <= 10"}
            )
        except DocumentValidationError as e:
            # Should either pass or give clear error about comparison symbols
            assert "comparison operators" in str(e) or "Content contains" in str(e)

    def test_append_entry_with_escaped_comparison_symbols(self):
        """Test append_entry metadata processing with comparison symbols."""
        test_meta = {
            "priority": "value > 5",
            "test_param": "normal_value"
        }

        result = _normalise_meta(test_meta)
        result_dict = dict(result)

        # Comparison operators should be escaped
        assert result_dict["priority"] != "value > 5"
        assert "\\" in result_dict.get("priority", "")

    def test_enhanced_validator_integration(self):
        """Test enhanced parameter validator integration."""
        validator = create_manage_docs_validator()

        # Test complex parameter validation
        try:
            doc = validator.validate_string_param("test_doc", "doc")
            action = validator.validate_enum_param("append", "action", ["append", "replace"])
            metadata = validator.validate_metadata({"key": "value"}, "metadata")

            assert doc == "test_doc"
            assert action == "append"
            assert metadata == {"key": "value"}

        except ParameterValidationError as e:
            pytest.fail(f"Enhanced validation failed unexpectedly: {e}")


class TestErrorHandlingAndMessages:
    """Test error handling and message quality."""

    def test_document_validation_error_messages(self):
        """Test that validation error messages are clear and actionable."""
        try:
            _validate_inputs(
                doc="",
                action="invalid_action",
                section=None,
                content="Test",
                template=None,
                metadata={}
            )
        except (DocumentValidationError, ParameterValidationError) as e:
            error_msg = str(e)
            # Should contain helpful information
            assert len(error_msg) > 10  # Not too short
            assert ("Invalid action" in error_msg or
                   "required" in error_msg or
                   "at least" in error_msg or
                   "manage_docs" in error_msg)

    def test_parameter_validation_error_context(self):
        """Test that parameter validation errors include tool context."""
        validator = create_manage_docs_validator()

        try:
            validator.validate_string_param(123, "test_param")
        except ParameterValidationError as e:
            error_msg = str(e)
            # Should include tool name for context
            assert "manage_docs" in error_msg

    def test_suggestions_in_error_messages(self):
        """Test that error messages include helpful suggestions."""
        validator = create_manage_docs_validator()

        error = validator.create_validation_error(
            "Invalid parameter",
            param_name="test_param",
            suggestion="Use a valid string value"
        )

        error_msg = str(error)
        assert "Invalid parameter" in error_msg
        assert "Suggestion:" in error_msg
        assert "valid string value" in error_msg


if __name__ == "__main__":
    # Run tests with pytest
    pytest.main([__file__, "-v"])
